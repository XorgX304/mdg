import os
from collections import OrderedDict
import pandas as pd
from flask import Flask, request
from backend.data_generation.awk_data_generator import AWKDataGenerator
from backend.data_generation.data_generator import DataGenerator


# Constants
AMP = '&'
EQ = '='
CSV = '.csv'
EOL = '\n'
COMMA = ','
DELIMITER = 'delimiter'
UTF = 'utf-8'
MAX_ROWS = 250000

# Using camel case just to match front end arguments
# Option arguments for SQL/XML/CSV
FILE_TYPE_OPTIONS = ('tableName', 'createTable', 'delimiter', 'sqlExtension')

# Option arguments for data types Int/Float/Boolean/Gender
DATA_TYPE_OPTIONS = ('dateRangeStart', 'dateRangeEnd', 'boolPercentage', 'intRangeMin',
                     'intRangeMax', 'floatRangeMin', 'floatRangeMax', 'decimalLimit', 'genderPercentage')

# Data types generated using AWK
AWK_GENERATED = ('auto-increment', 'random-float', 'random-int', 'timestamp', 'zipcode', 'phone', 'cc-number',
                 'cvv', 'balance', 'cc-exp', 'rgb')

# Instances
app = Flask(__name__, static_url_path='')  # Set static folder path
awk = AWKDataGenerator()
data_generator = DataGenerator()

delimiter_chars = {
    "comma": ",",
    "caret": "^",
    "semi": ";",
    "tab": "\t",
    "pipe": "|"
}


# Index
@app.route('/')
def index():
    return app.send_static_file('index.html')


# 404 #
@app.errorhandler(404)
def not_found():
    return app.send_static_file('error.html'), 404


# Generate POST handler
@app.route('/generate', methods=['POST'])
def generate():
    """Parse request parameters, generate files & upload file. Respond with download link"""
    # Decode request literal to utf8
    request_literal = request.get_data().decode(UTF)
    # Create on OrderedDict from the request literal
    post_data = parse_post_data(request_literal)

    # Create headers list, awk generated headers list & and file type special options dictionary
    headers = list(post_data.keys())
    awk_generated = list(header for header in headers if post_data.get(header) in AWK_GENERATED)
    # Extract specific data types options
    options_dict = {key: post_data.get(key) for key in headers for option in DATA_TYPE_OPTIONS if option in key}
    # Extract options regarding file type
    for option in FILE_TYPE_OPTIONS:
        if option in headers:
            options_dict[option] = post_data.get(option)
    headers = [header for header in headers if header not in options_dict.keys()]
    # Now headers contain all column names and options_dict contains all special file/data options

    # Extract file name, type and number of rows
    filename = post_data.get(headers.pop()) + CSV
    num_rows = post_data.get(headers.pop())
    file_type = post_data.get(headers.pop())
    if num_rows > MAX_ROWS or len(headers) > 10:
        return "Illegel requests", 400

    # Create an empty file with headers
    with open(filename, 'w') as file:
        file.write(COMMA.join(headers) + EOL)

    # Write file
    write_awk_generated(headers, awk_generated, post_data, num_rows, filename, options_dict)

    # Check if file needs to be converted from CSV
    if not is_csv(file_type):
        filename = file_conversion(file_type, filename, options_dict)
    return filename


def parse_post_data(request_data):
    """
    Creates an ordered dict containing the post request files.
    Uses literal request files (not parsed) due to parsed files's order being mixed which affects
    the user's wanted order
    """
    # Split literal request files
    split_data = [element.split(EQ) for element in request_data.split(AMP)]
    post_data = OrderedDict()
    for group in split_data:
        post_data[group[0]] = group[1]
    return post_data


def write_awk_generated(headers, awk_generated, post_data, num_rows, filename, options):
    os.system(awk.create_awk_statement(post_data, headers, num_rows, filename, options))
    # If all columns are generated by AWK, writing to file is done
    if all([column in awk_generated for column in headers]):
        pass
    # Else call write_python_generated func with python_generated column set
    else:
        python_generated = set(headers) - set(awk_generated)
        # Get delimiter or set default one
        delimiter = delimiter_chars.get(options.get(DELIMITER), COMMA)
        write_python_generated(filename, post_data, python_generated, delimiter, options)
    return


def write_python_generated(filename, post_data, python_generated, delimiter, options):
    """Write non-AWK column files using Pandas"""
    df = pd.read_csv(filename, sep=COMMA)
    for header in python_generated:
        try:
            callback = data_generator.commands.get(post_data.get(header))
            # Get corresponding value for data type and apply to the entire column - whether its a function or list
            df[header] = df[header].apply(
                lambda x: data_generator.rand_element(callback)
                if isinstance(callback, list) else callback(header, options))
        except TypeError as err:
            print(err)
            pass  # TODO log
    # Write the csv with new values and delimiter
    df.to_csv(filename, sep=delimiter, index=False)
    return


def is_csv(file_type):
    """Check if file type is CSV"""
    return file_type == CSV


def file_conversion(file_type, filename, options):
    """Check file type and call appropriate conversion function"""
    if file_type == '.xml':
        filename = convert_to_xml(filename)
    elif file_type == '.json':
        filename = convert_to_json(filename)
    elif file_type == '.sql':
        filename = convert_to_sql(filename, options)
    return filename


def convert_to_xml(filename):
    """Call c2x-cmd plugin to convert CSV to XML"""
    xml_file = filename.split('.')[0] + '.xml'
    os.system('c2x/c2x-cmd -s:{0} -sep{1} -t'.format(xml_file, COMMA))
    return xml_file


def convert_to_json(filename):
    """Call csv2json library to convert CSV to JSON"""
    json_file = filename.split('.')[0] + '.json'
    os.system('csv2json {0} > {1} --delimiter="{2}"'.format(filename, json_file, COMMA))
    return json_file


def convert_to_sql(filename, options):
    sql_file = filename.split('.')[0] + options.get('sqlExtension')
    # Run conversion to SQL here
    return sql_file
